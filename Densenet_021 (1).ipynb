{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EFEDFEY1aTWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Arwlw-AjZy1p"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import datasets, models, transforms\n",
        "from tempfile import TemporaryDirectory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of classes\n",
        "n_class = 5\n",
        "\n",
        "# Set root path to the dataset\n",
        "root_path = \"/content/drive/MyDrive/4th year, 2nd sem/PD/Dataset/kneeKL224/\"\n",
        "\n",
        "# List all folders\n",
        "folder_set = os.listdir(root_path)\n",
        "image_path_list = []\n",
        "label_list = []\n",
        "folder_list = []\n",
        "\n",
        "# For each folder, get the image path and labels\n",
        "for folder in folder_set:\n",
        "    for label in range(n_class):\n",
        "        # Get all the images path inside the current folder\n",
        "        image_list = os.listdir(f\"{root_path}{folder}/{label}\")\n",
        "        # Add to the image path list\n",
        "        image_path_list += [f\"{root_path}{folder}/{label}/\"+ path for path in image_list]\n",
        "        # Add labels to the label list\n",
        "        label_list += [label] * len(image_list)\n",
        "        # Add folder to the folder list\n",
        "        folder_list += [folder] * len(image_list)\n",
        "\n",
        "# Convert to dataframe\n",
        "dataset_dict = pd.DataFrame({\"filepath\" : image_path_list, \"folder\": folder_list, \"label\": label_list})\n",
        "\n",
        "# Group by folder and label, and count filepaths\n",
        "dataset_dict.groupby([\"folder\", \"label\"])[\"filepath\"].count()"
      ],
      "metadata": {
        "id": "JjnhG2ItZ2iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "dataloaders = {}\n",
        "dataset_sizes = {}\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(root_path, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n",
        "for sample in ['train', 'val', 'test']:\n",
        "    idx = [i for i in range(len(image_datasets[sample])) if image_datasets[sample].imgs[i][1] not in [1,2,3]] # Exclude unused classes\n",
        "    subset = Subset(image_datasets[sample], idx)\n",
        "    dataloaders[sample] = torch.utils.data.DataLoader(subset, batch_size=4, shuffle=True, num_workers=4)\n",
        "    dataset_sizes[sample] = len(idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-CyCuPzagT2",
        "outputId": "05bb95bb-1f84-4a1c-e560-15d6ef0922cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load pre-trained DenseNet-201 model\n",
        "model_densenet = models.densenet201(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer to match your task\n",
        "num_ftrs = model_densenet.classifier.in_features\n",
        "n_class = 5  # Assuming there are 5 classes\n",
        "model_densenet.classifier = nn.Linear(num_ftrs, n_class)\n",
        "\n",
        "# Set requires_grad to True for all parameters of the final layer\n",
        "for param in model_densenet.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Move the model to the appropriate device (GPU or CPU)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_densenet = model_densenet.to(device)\n",
        "\n",
        "# Set up optimizer and loss function\n",
        "optimizer_densenet = optim.SGD(model_densenet.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion_densenet = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set up learning rate scheduler if needed\n",
        "exp_lr_scheduler_densenet = lr_scheduler.StepLR(optimizer_densenet, step_size=7, gamma=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klIdwb92aop9",
        "outputId": "50434680-360c-40ad-c245-59064f69b611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /root/.cache/torch/hub/checkpoints/densenet201-c1103571.pth\n",
            "100%|██████████| 77.4M/77.4M [00:03<00:00, 26.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import copy\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import pandas as pd\n",
        "from tempfile import TemporaryDirectory\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Initialize dictionaries to store metrics\n",
        "    metrics = {'train': {'loss': [], 'acc': []}, 'val': {'loss': [], 'acc': []}}\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                metrics[phase]['loss'].append(epoch_loss)\n",
        "                metrics[phase]['acc'].append(epoch_acc)\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:.4f}')\n",
        "\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(metrics['train']['acc'], label='Train Accuracy')\n",
        "    plt.plot(metrics['val']['acc'], label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(metrics['train']['loss'], label='Train Loss')\n",
        "    plt.plot(metrics['val']['loss'], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Gpi2oXdaaoyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_densenet = train_model(model_densenet, criterion_densenet, optimizer_densenet,\n",
        "                             exp_lr_scheduler_densenet, num_epochs=21)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiFpQCmwa2Tm",
        "outputId": "ec02c9cc-bced-4d5c-f3f7-c8b113dd35af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/20\n",
            "----------\n",
            "train Loss: 0.2049 Acc: 0.9382\n",
            "val Loss: 0.1022 Acc: 0.9549\n",
            "\n",
            "Epoch 1/20\n",
            "----------\n",
            "train Loss: 0.1030 Acc: 0.9691\n",
            "val Loss: 0.0491 Acc: 0.9915\n",
            "\n",
            "Epoch 2/20\n",
            "----------\n",
            "train Loss: 0.0917 Acc: 0.9723\n",
            "val Loss: 0.0155 Acc: 0.9915\n",
            "\n",
            "Epoch 3/20\n",
            "----------\n",
            "train Loss: 0.0658 Acc: 0.9813\n",
            "val Loss: 0.0313 Acc: 0.9915\n",
            "\n",
            "Epoch 4/20\n",
            "----------\n",
            "train Loss: 0.0684 Acc: 0.9801\n",
            "val Loss: 0.0185 Acc: 0.9972\n",
            "\n",
            "Epoch 5/20\n",
            "----------\n",
            "train Loss: 0.0644 Acc: 0.9793\n",
            "val Loss: 0.0129 Acc: 0.9944\n",
            "\n",
            "Epoch 6/20\n",
            "----------\n",
            "train Loss: 0.0507 Acc: 0.9870\n",
            "val Loss: 0.0079 Acc: 0.9972\n",
            "\n",
            "Epoch 7/20\n",
            "----------\n",
            "train Loss: 0.0539 Acc: 0.9850\n",
            "val Loss: 0.0051 Acc: 1.0000\n",
            "\n",
            "Epoch 8/20\n",
            "----------\n",
            "train Loss: 0.0446 Acc: 0.9862\n",
            "val Loss: 0.0070 Acc: 0.9972\n",
            "\n",
            "Epoch 9/20\n",
            "----------\n",
            "train Loss: 0.0415 Acc: 0.9878\n",
            "val Loss: 0.0054 Acc: 0.9972\n",
            "\n",
            "Epoch 10/20\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YiAMAOu-4HdZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}